{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deduplication & Record Linkage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook shows how to use TD IDF, FUZZY to both dedupe and match records at scale besides K Nearest Neighbour algorithm as an alternative closeness measure "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Data in the real world is messy. Dealing with messy data sets is painful and burns through time which could be spent analysing the data itself.\n",
    "\n",
    "![https://www.acronis.com/en-us/articles/deduplication/](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTc_jlg2hrSRYqdenJdv7p_4Xo6Uj-qqCPpx4ANHI2hNkA8TJQPJQ&s)\n",
    "\n",
    "- **Deduplication**. Aligning similar categories or entities in a data set (for example, we may need to combine ‘D J Trump’, ‘D. Trump’ and ‘Donald Trump’ into the same entity).\n",
    "- **Record Linkage**. Joining data sets on a particular entity (for example, joining records of ‘D J Trump’ to a URL of his Wikipedia page)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important Talk by: presented at PyBay2018 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"1280\" height=\"720\" src=\"https://www.youtube.com/embed/McsTWXeURhA\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"1280\" height=\"720\" src=\"https://www.youtube.com/embed/McsTWXeURhA\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Record Deduplication**, or more generally, Record Linkage is the task of finding which records refer to the same entity, like a person or a company. It's used mainly when there isn't a unique identifier in records like Social Security Number for US citizens\n",
    "[Dedupe.io](https://dedupe.io)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<html>\n",
    "<body>\n",
    "\n",
    "<p><font size=\"5\" color=\"Purple\">If you find this kernel useful or interesting, please don't forget to upvote the kernel =)\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import time\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Visualization', 'sqlite3_practice.ipynb', '.DS_Store', 'data_transport-nodes.csv', 'TwitterAPI_Practice.ipynb', 'deduping-record-linkage.ipynb', 'data_transport-relationships.csv', 'world_sentiment.ipynb', '__pycache__', 'DataCrawling_API', 'example.html', 'meteorites.ipynb', '.ipynb_checkpoints', 'Unit_4_Challenge_Tier_3_Jae_Choi.ipynb', 'Big_Mountain', 'DataWrangling', 'DataScienceGuidedCapstone']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './sec__edgar_company_info.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bd5a154f2b51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'sec__edgar_company_info.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1872\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1873\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1874\u001b[0;31m                 \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1875\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './sec__edgar_company_info.csv'"
     ]
    }
   ],
   "source": [
    "root = './'\n",
    "\n",
    "data = pd.read_csv(root + 'sec__edgar_company_info.csv',encoding='latin')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glimpse of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data  (663000, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Size of data ',data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line Number</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Company CIK Key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>!J INC</td>\n",
       "      <td>1438823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>#1 A LIFESAFER HOLDINGS, INC.</td>\n",
       "      <td>1509607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>#1 ARIZONA DISCOUNT PROPERTIES LLC</td>\n",
       "      <td>1457512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>#1 PAINTBALL CORP</td>\n",
       "      <td>1433777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>$ LLC</td>\n",
       "      <td>1427189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Line Number                        Company Name  Company CIK Key\n",
       "0  1            !J INC                              1438823        \n",
       "1  2            #1 A LIFESAFER HOLDINGS, INC.       1509607        \n",
       "2  3            #1 ARIZONA DISCOUNT PROPERTIES LLC  1457512        \n",
       "3  4            #1 PAINTBALL CORP                   1433777        \n",
       "4  5            $ LLC                               1427189        "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company Name    657160\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.select_dtypes('object').apply(pd.Series.nunique, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FuzzyWuzzy\n",
    "\n",
    "In computer science, fuzzy string matching is the technique of finding strings that match a pattern approximately (rather than exactly). In another word, fuzzy string matching is a type of search that will find matches even when users misspell words or enter only partial words for the search. It is also known as approximate string matching.\n",
    "\n",
    "\n",
    "- Fuzzywuzzy is a Python library uses **Levenshtein Distance** to calculate the differences between sequences in a simple-to-use package.\n",
    "- Instalation: !pip install fuzzywuzzy, import: from fuzzywuzzy import fuzz, from fuzzywuzzy import process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fuzzywuzzy in /opt/conda/lib/python3.6/site-packages (0.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install fuzzywuzzy\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line Number</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Company CIK Key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>662995</th>\n",
       "      <td>662996</td>\n",
       "      <td>ZZ GLOBAL LLC</td>\n",
       "      <td>1501460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662996</th>\n",
       "      <td>662997</td>\n",
       "      <td>ZZIF 2008 INVESTMENT LLC</td>\n",
       "      <td>1448632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662997</th>\n",
       "      <td>662998</td>\n",
       "      <td>ZZLL INFORMATION TECHNOLOGY, INC</td>\n",
       "      <td>1365357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662998</th>\n",
       "      <td>662999</td>\n",
       "      <td>ZZX, LLC</td>\n",
       "      <td>1691924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662999</th>\n",
       "      <td>663000</td>\n",
       "      <td>ZZYZX ZZAZX ZZOZX INC</td>\n",
       "      <td>1184274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Line Number                      Company Name  Company CIK Key\n",
       "662995  662996       ZZ GLOBAL LLC                     1501460        \n",
       "662996  662997       ZZIF 2008 INVESTMENT LLC          1448632        \n",
       "662997  662998       ZZLL INFORMATION TECHNOLOGY, INC  1365357        \n",
       "662998  662999       ZZX, LLC                          1691924        \n",
       "662999  663000       ZZYZX ZZAZX ZZOZX INC             1184274        "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ratio** , compares the entire string similarity, in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.ratio('ZZ GLOBAL LLC', 'ZZLL INFORMATION TECHNOLOGY, INC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is telling us that the 'ZZ GLOBAL LLC' and 'ZZLL INFORMATION TECHNOLOGY, INC' pair are about **36%** the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.ratio('ZZ GLOBAL LLC', 'ZZX, LLC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is telling us that the 'ZZ GLOBAL LLC' and 'ZZX, LLC' pair are about **57%** the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**partial_ratio** , compares partial string similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We are still using the same data pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.partial_ratio('ZZ GLOBAL LLC', 'ZZLL INFORMATION TECHNOLOGY, INC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.partial_ratio('ZZ GLOBAL LLC', 'ZZX, LLC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**token_sort_ratio** , ignores word order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.token_sort_ratio('ZZ GLOBAL LLC', 'ZZLL INFORMATION TECHNOLOGY, INC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.token_sort_ratio('ZZ GLOBAL LLC', 'ZZX, LLC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**token_set_ratio** , ignores duplicated words. It is similar with token sort ratio, but a little bit more flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.token_set_ratio('ZZ GLOBAL LLC', 'ZZLL INFORMATION TECHNOLOGY, INC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.token_set_ratio('ZZ GLOBAL LLC', 'ZZX, LLC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF & N-Grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF-IDF** is a method to generate features from text by multiplying the frequency of a term (usually a word) in a document (the Term Frequency, or TF) by the importance (the Inverse Document Frequency or IDF) of the same term in an entire corpus. This last term weights less important words (e.g. the, it, and etc) down, and words that don’t occur frequently up. IDF is calculated as:\n",
    "\n",
    "\n",
    "\n",
    "<html>\n",
    "<body>\n",
    "\n",
    "<p><font size=\"4\" color=\"Purple\">IDF(t) = log_e(Total number of documents / Number of documents with term t in it) \n",
    "\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Grams  & De-Duplication\n",
    "\n",
    "While the terms in **TF-IDF** are usually words, this is not a necessity. In our case using words as terms wouldn’t help us much, as most company names only contain one or two words. This is why we will use n-grams: sequences of N contiguous items, in this case characters. The following function cleans a string and generates all n-grams in this string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ftfy in /opt/conda/lib/python3.6/site-packages (5.6)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from ftfy) (0.1.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install ftfy # amazing text cleaning for decode issues.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from ftfy import fix_text\n",
    "\n",
    "def ngrams(string, n=3):\n",
    "    string = fix_text(string) # fix text\n",
    "    string = string.encode(\"ascii\", errors=\"ignore\").decode() #remove non ascii chars\n",
    "    string = string.lower()\n",
    "    chars_to_remove = [\")\",\"(\",\".\",\"|\",\"[\",\"]\",\"{\",\"}\",\"'\"]\n",
    "    rx = '[' + re.escape(''.join(chars_to_remove)) + ']'\n",
    "    string = re.sub(rx, '', string)\n",
    "    string = string.replace('&', 'and')\n",
    "    string = string.replace(',', ' ')\n",
    "    string = string.replace('-', ' ')\n",
    "    string = string.title() # normalise case - capital at start of each word\n",
    "    string = re.sub(' +',' ',string).strip() # get rid of multiple spaces and replace with a single\n",
    "    string = ' '+ string +' ' # pad names for ngrams...\n",
    "    string = re.sub(r'[,-./]|\\sBD',r'', string)\n",
    "    ngrams = zip(*[string[i:] for i in range(n)])\n",
    "    return [''.join(ngram) for ngram in ngrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 3-grams in \"McDonalds\":\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' Mc', 'Mcd', 'cdo', 'don', 'ona', 'nal', 'ald', 'lds', 'ds ']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('All 3-grams in \"McDonalds\":')\n",
    "ngrams('McDonalds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The code to generate the matrix of TF-IDF values for each is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "company_names = data['Company Name'].unique()\n",
    "vectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams)\n",
    "tf_idf_matrix = vectorizer.fit_transform(company_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting matrix is very sparse as most terms in the corpus will not appear in most company names. Scikit-learn deals with this nicely by returning a sparse CSR matrix.\n",
    "\n",
    "You can see the first row (**“!J INC”**) contains three terms for the columns 11, 16196, and 15541."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line Number</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Company CIK Key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>!J INC</td>\n",
       "      <td>1438823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>#1 A LIFESAFER HOLDINGS, INC.</td>\n",
       "      <td>1509607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>#1 ARIZONA DISCOUNT PROPERTIES LLC</td>\n",
       "      <td>1457512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>#1 PAINTBALL CORP</td>\n",
       "      <td>1433777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>$ LLC</td>\n",
       "      <td>1427189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Line Number                        Company Name  Company CIK Key\n",
       "0  1            !J INC                              1438823        \n",
       "1  2            #1 A LIFESAFER HOLDINGS, INC.       1509607        \n",
       "2  3            #1 ARIZONA DISCOUNT PROPERTIES LLC  1457512        \n",
       "3  4            #1 PAINTBALL CORP                   1433777        \n",
       "4  5            $ LLC                               1427189        "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(657160, 37119)   (0, 905)\t0.11747342651928797\n",
      "  (0, 12077)\t0.11822512321094272\n",
      "  (0, 27459)\t0.11764068247526939\n",
      "  (0, 433)\t0.1807883223657008\n",
      "  (0, 5217)\t0.1968010893368829\n",
      "  (0, 29004)\t0.13214756337891406\n",
      "  (0, 22076)\t0.224458121498971\n",
      "  (0, 1159)\t0.22889154809271653\n",
      "  (0, 15869)\t0.4290310422526812\n",
      "  (0, 944)\t0.19804561475450264\n",
      "  (0, 12618)\t0.240533593422862\n",
      "  (0, 23081)\t0.21584616621620273\n",
      "  (0, 22404)\t0.24354580225181\n",
      "  (0, 25639)\t0.20880523548032526\n",
      "  (0, 19630)\t0.28118717766504064\n",
      "  (0, 706)\t0.17828578761405625\n",
      "  (0, 9288)\t0.2012718937765515\n",
      "  (0, 32099)\t0.2052050687748287\n",
      "  (0, 30368)\t0.21145588141241375\n",
      "  (0, 34500)\t0.21093965479359214\n",
      "  (0, 30536)\t0.23108893126820304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' #1',\n",
       " '#1 ',\n",
       " '1 P',\n",
       " ' Pa',\n",
       " 'Pai',\n",
       " 'ain',\n",
       " 'int',\n",
       " 'ntb',\n",
       " 'tba',\n",
       " 'bal',\n",
       " 'all',\n",
       " 'll ',\n",
       " 'l C',\n",
       " ' Co',\n",
       " 'Cor',\n",
       " 'orp',\n",
       " 'rp ']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( tf_idf_matrix.shape, tf_idf_matrix[5] )\n",
    "# Check if this makes sense:\n",
    "\n",
    "ngrams('#1 PAINTBALL CORP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The last term (**‘ORP’**) has a relatively low value, **0.22892**, which makes sense as this term will appear often in the corpus, thus receiving a lower IDF weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('07 GRAEME HALL/VINES OF JUSTICE, LLC', 86)\n",
      "SELFTIMED: 0.09808468818664551\n",
      "Estimated hours to complete for 1000 rows of  dataset: 0.027218500971794127\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "print(process.extractOne('Ministry of Justice', company_names[0:999])) #org names is our list of organization names\n",
    "t = time.time()-t1\n",
    "print(\"SELFTIMED:\", t)\n",
    "print(\"Estimated hours to complete for 1000 rows of  dataset:\", (t*len(company_names[0:999]))/60/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record linkage and a different approach\n",
    "> In the below section we will see how this is achieved and also use the K Nearest Neighbour algorithm as an alternative closeness measure.\n",
    "The dataset we would like to join on is a set of ‘clean’ organization names created by the Office for National Statistics (ONS):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/1014/1*k45HFixH1Q-qxxH1i2rsxQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be shown in the code below, the only difference in this approach is to transform the messy data set using the tdif matrix which has been learned on the clean data set.\n",
    "\n",
    "The **‘getNearestN’** then uses Scikit’s implementation of K Nearest Neighbours to find the closest matches in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "root2 = '../input/gov-names/'\n",
    "clean_org_names = pd.read_excel(root2 + 'Gov Orgs ONS.xlsx')\n",
    "clean_org_names = clean_org_names.iloc[:, 0:6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vecorizing the data - this could take a few minutes for large datasets...\n",
      "Vecorizing completed...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "org_name_clean = clean_org_names['Institutions'].unique()\n",
    "\n",
    "print('Vecorizing the data - this could take a few minutes for large datasets...')\n",
    "vectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams, lowercase=False)\n",
    "tfidf = vectorizer.fit_transform(org_name_clean)\n",
    "print('Vecorizing completed...')\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "nbrs = NearestNeighbors(n_neighbors=1, n_jobs=-1).fit(tfidf)\n",
    "\n",
    "org_column = 'Company Name' #column to match against in the messy data\n",
    "unique_org = set(data[org_column].values) # set used for increased performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting nearest n...\n",
      "COMPLETED IN: 195.79840731620789\n",
      "finding matches...\n",
      "Building data frame...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "###matching query:\n",
    "def getNearestN(query):\n",
    "    queryTFIDF_ = vectorizer.transform(query)\n",
    "    distances, indices = nbrs.kneighbors(queryTFIDF_)\n",
    "    return distances, indices\n",
    "\n",
    "import time\n",
    "t1 = time.time()\n",
    "print('getting nearest n...')\n",
    "distances, indices = getNearestN(unique_org)\n",
    "t = time.time()-t1\n",
    "print(\"COMPLETED IN:\", t)\n",
    "\n",
    "unique_org = list(unique_org) #need to convert back to a list\n",
    "print('finding matches...')\n",
    "matches = []\n",
    "for i,j in enumerate(indices):\n",
    "    temp = [round(distances[i][0],2), clean_org_names.values[j][0][0],unique_org[i]]\n",
    "    matches.append(temp)\n",
    "\n",
    "print('Building data frame...')  \n",
    "matches = pd.DataFrame(matches, columns=['Match confidence (lower is better)','Matched name','Origional name'])\n",
    "print('Done') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match confidence (lower is better)</th>\n",
       "      <th>Matched name</th>\n",
       "      <th>Origional name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.22</td>\n",
       "      <td>National Institute of Health and Care Excellence</td>\n",
       "      <td>JOXCEL, INC.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.19</td>\n",
       "      <td>Aire Valley Mortgages 2006-1 plc</td>\n",
       "      <td>LARRON 2006 LTD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.25</td>\n",
       "      <td>Gaming Board for Great Britain</td>\n",
       "      <td>ADKIN GREGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.27</td>\n",
       "      <td>BPL Holdings Ltd (Formerly Plasma Resources UK Ltd)</td>\n",
       "      <td>REITSMA RAYMOND E.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.24</td>\n",
       "      <td>BBC Worldwide (Germany) GMBH [Germany] (s BBCW)</td>\n",
       "      <td>TRIAD SHERMAN LLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.09</td>\n",
       "      <td>Big Society Capital</td>\n",
       "      <td>TROUT CAPITAL LLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.23</td>\n",
       "      <td>English Partnerships (LP) Limited</td>\n",
       "      <td>MURRELLS INLET GP, LP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.20</td>\n",
       "      <td>Community Fund</td>\n",
       "      <td>TEKA PRIVATE EQUITY FUND I, L.P.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.06</td>\n",
       "      <td>Government Annuities Investment Fund</td>\n",
       "      <td>SEARS GOVERNMENT INVESTMENT TRUST U S TREASURY SERIES 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.07</td>\n",
       "      <td>Natural Resources Wales</td>\n",
       "      <td>ORE-MORE RESOURCES INC.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Match confidence (lower is better)  \\\n",
       "0  1.22                                 \n",
       "1  1.19                                 \n",
       "2  1.25                                 \n",
       "3  1.27                                 \n",
       "4  1.24                                 \n",
       "5  1.09                                 \n",
       "6  1.23                                 \n",
       "7  1.20                                 \n",
       "8  1.06                                 \n",
       "9  1.07                                 \n",
       "\n",
       "                                          Matched name  \\\n",
       "0  National Institute of Health and Care Excellence      \n",
       "1  Aire Valley Mortgages 2006-1 plc                      \n",
       "2  Gaming Board for Great Britain                        \n",
       "3  BPL Holdings Ltd (Formerly Plasma Resources UK Ltd)   \n",
       "4  BBC Worldwide (Germany) GMBH [Germany] (s BBCW)       \n",
       "5  Big Society Capital                                   \n",
       "6  English Partnerships (LP) Limited                     \n",
       "7  Community Fund                                        \n",
       "8  Government Annuities Investment Fund                  \n",
       "9  Natural Resources Wales                               \n",
       "\n",
       "                                            Origional name  \n",
       "0  JOXCEL, INC.                                             \n",
       "1  LARRON 2006 LTD                                          \n",
       "2  ADKIN GREGG                                              \n",
       "3  REITSMA RAYMOND E.                                       \n",
       "4  TRIAD SHERMAN LLC                                        \n",
       "5  TROUT CAPITAL LLC                                        \n",
       "6  MURRELLS INLET GP, LP                                    \n",
       "7  TEKA PRIVATE EQUITY FUND I, L.P.                         \n",
       "8  SEARS GOVERNMENT INVESTMENT TRUST U S TREASURY SERIES 5  \n",
       "9  ORE-MORE RESOURCES INC.                                  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding close matches through getNearestN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match confidence (lower is better)</th>\n",
       "      <th>Matched name</th>\n",
       "      <th>Origional name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20073</th>\n",
       "      <td>0.00</td>\n",
       "      <td>Lloyds Bank plc</td>\n",
       "      <td>LLOYDS BANK PLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564544</th>\n",
       "      <td>0.00</td>\n",
       "      <td>TSB Bank plc</td>\n",
       "      <td>TSB BANK PLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567753</th>\n",
       "      <td>0.00</td>\n",
       "      <td>Lloyds Banking Group plc</td>\n",
       "      <td>LLOYDS BANKING GROUP PLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436975</th>\n",
       "      <td>0.00</td>\n",
       "      <td>Bradford &amp; Bingley plc</td>\n",
       "      <td>BRADFORD &amp; BINGLEY PLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189613</th>\n",
       "      <td>0.00</td>\n",
       "      <td>Granite Mortgages 01-2 plc</td>\n",
       "      <td>GRANITE MORTGAGES 01-2 PLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354809</th>\n",
       "      <td>1.34</td>\n",
       "      <td>Littlehampton Harbour Board</td>\n",
       "      <td>ABU GHAZALEH OUSSAMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373410</th>\n",
       "      <td>1.34</td>\n",
       "      <td>Wider Health Working Group</td>\n",
       "      <td>PBG GRUPO EMBOTELLADOR HISPANO - MEXICANO SL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422001</th>\n",
       "      <td>1.34</td>\n",
       "      <td>Civil Justice Council</td>\n",
       "      <td>GOLEMBIEWSKI MICHAEL JOSEPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610674</th>\n",
       "      <td>1.34</td>\n",
       "      <td>Joint Committee on Vaccination and Immunisation</td>\n",
       "      <td>ZACCAGNINO JOSEPH A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128942</th>\n",
       "      <td>1.34</td>\n",
       "      <td>Tunbridge Wells Borough Council</td>\n",
       "      <td>WEINBRECHT JOSEPH F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>657160 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Match confidence (lower is better)  \\\n",
       "20073   0.00                                 \n",
       "564544  0.00                                 \n",
       "567753  0.00                                 \n",
       "436975  0.00                                 \n",
       "189613  0.00                                 \n",
       "...      ...                                 \n",
       "354809  1.34                                 \n",
       "373410  1.34                                 \n",
       "422001  1.34                                 \n",
       "610674  1.34                                 \n",
       "128942  1.34                                 \n",
       "\n",
       "                                           Matched name  \\\n",
       "20073   Lloyds Bank plc                                   \n",
       "564544  TSB Bank plc                                      \n",
       "567753  Lloyds Banking Group plc                          \n",
       "436975  Bradford & Bingley plc                            \n",
       "189613  Granite Mortgages 01-2 plc                        \n",
       "...                            ...                        \n",
       "354809  Littlehampton Harbour Board                       \n",
       "373410  Wider Health Working Group                        \n",
       "422001  Civil Justice Council                             \n",
       "610674  Joint Committee on Vaccination and Immunisation   \n",
       "128942  Tunbridge Wells Borough Council                   \n",
       "\n",
       "                                      Origional name  \n",
       "20073   LLOYDS BANK PLC                               \n",
       "564544  TSB BANK PLC                                  \n",
       "567753  LLOYDS BANKING GROUP PLC                      \n",
       "436975  BRADFORD & BINGLEY PLC                        \n",
       "189613  GRANITE MORTGAGES 01-2 PLC                    \n",
       "...                            ...                    \n",
       "354809  ABU GHAZALEH OUSSAMA                          \n",
       "373410  PBG GRUPO EMBOTELLADOR HISPANO - MEXICANO SL  \n",
       "422001  GOLEMBIEWSKI MICHAEL JOSEPH                   \n",
       "610674  ZACCAGNINO JOSEPH A                           \n",
       "128942  WEINBRECHT JOSEPH F                           \n",
       "\n",
       "[657160 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches.sort_values('Match confidence (lower is better)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In summary, tf-idf can be a highly effective and highly performant way of cleaning, deduping and matching data when dealing with larger record counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**\n",
    "\n",
    "http://towardsdatascience.com/natural-language-processing-for-fuzzy-string-matching-with-python-6632b7824c49,\n",
    "\n",
    "https://towardsdatascience.com/fuzzy-matching-at-scale-84f2bfd0c536,\n",
    "\n",
    "https://bergvca.github.io/2017/10/14/super-fast-string-matching.html?source=post_page-----84f2bfd0c536---------------------- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<html>\n",
    "<body>\n",
    "\n",
    "<p><font size=\"5\" color=\"Red\">If you like my kernel please consider upvoting it</font></p>\n",
    "<p><font size=\"4\" color=\"Green\">Don't hesitate to give your suggestions in the comment section</font></p>\n",
    "\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
